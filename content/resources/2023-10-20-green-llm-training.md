---
title: "Green Training of Large Language Models: Challenges and Techniques"
publication_date: 2023-10-20
authors:
  - title: Zhihui Xie
    organization: tsinghua-university/_index
  - title: Tao Ge
    organization: microsoft-research-asia/_index
  - title: Furu Wei
    organization: microsoft-research-asia/_index
categories:
  - sustainable/_index
  - ai/_index
tags:
  - Green AI
  - LLM training
  - Energy efficiency
  - Model optimization
  - Sustainable computing
resource_type: research
summary: |
  This research investigates techniques for making the training of large language models more environmentally sustainable without compromising model performance.

  The authors propose novel methods for reducing energy consumption during training, including adaptive batch sizing, efficient model architectures, and intelligent resource allocation.

  The study provides extensive empirical analysis of different training strategies and their impact on both model quality and environmental footprint.
source_url: https://arxiv.org/abs/2310.12534
source_document: https://arxiv.org/pdf/2310.12534.pdf
source_organizations:
  - tsinghua-university/_index
  - microsoft-research-asia/_index
language: en
--- 