---
title: "Mission: Impossible Language Models"
publication_date: 2024-01-12
authors:
  - title: Julie Kallini
    organization: stanford-university/_index
  - title: Isabel Papadimitriou
    organization: stanford-university/_index
  - title: Richard Futrell
    organization: university-california-irvine/_index
  - title: Kyle Mahowald
    organization: university-texas-austin/_index
  - title: Christopher Potts
    organization: stanford-university/_index
categories:
  - ai/_index
tags:
  - large language models
  - linguistics
  - GPT-2
  - cognitive science
  - natural language processing
  - language acquisition
resource_type: article
summary: |
  Chomsky and others have claimed that large language models (LLMs) are equally capable of learning languages that are possible and impossible for humans to learn. However, there is very little published experimental evidence to support such a claim.

  This study develops a set of synthetic impossible languages of differing complexity, each designed by systematically altering English data with unnatural word orders and grammar rules. These languages lie on an impossibility continuum: at one end are languages that are inherently impossible (random and irreversible shuffles of English words), and on the other, languages considered impossible in linguistics, particularly those with rules based on counting word positions.

  A wide range of evaluations assess the capacity of GPT-2 small models to learn these uncontroversially impossible languages, performed at various stages throughout training to compare the learning process for each language. The core finding is that GPT-2 struggles to learn impossible languages compared to English as a control, challenging Chomsky's claim.

  The authors hope their approach opens a productive line of inquiry in which different LLM architectures are tested on a variety of impossible languages, as tools for cognitive and typological investigations.
source_url: https://arxiv.org/abs/2401.06416
source_document: https://arxiv.org/pdf/2401.06416
source_organizations:
  - stanford-university/_index
  - university-california-irvine/_index
  - university-texas-austin/_index
language: en
doi: https://doi.org/10.48550/arXiv.2401.06416
---

