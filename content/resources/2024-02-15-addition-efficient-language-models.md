---
title: "Addition is All You Need for Energy-efficient Language Models"
publication_date: 2024-02-15
authors:
  - title: Yuxuan Luo
    organization: stanford-university/_index
  - title: Christopher RÃ©
    organization: stanford-university/_index
categories:
  - sustainable/_index
  - ai/_index
tags:
  - Energy efficiency
  - Language models
  - Green AI
  - Model optimization
  - Sustainable computing
resource_type: research
summary: |
  This innovative research demonstrates how simple addition operations can be used to create more energy-efficient language models without sacrificing performance.

  The authors propose a novel architecture that significantly reduces computational complexity and energy consumption while maintaining model capabilities.

  The study provides empirical evidence showing substantial energy savings compared to traditional transformer architectures.
source_url: https://arxiv.org/abs/2402.03000
source_document: https://arxiv.org/pdf/2402.03000.pdf
source_organizations:
  - stanford-university/_index
language: en
--- 