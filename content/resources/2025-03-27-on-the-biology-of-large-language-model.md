---
title: "On the Biology of a Large Language Model"
publication_date: 2025-03-27
authors:
  - title: Jack Lindsey
    organization: anthropic/_index
    note: Lead Contributor
  - title: Wes Gurnee
    organization: anthropic/_index
    note: Core Contributor
  - title: Emmanuel Ameisen
    organization: anthropic/_index
    note: Core Contributor
  - title: Brian Chen
    organization: anthropic/_index
    note: Core Contributor
  - title: Adam Pearce
    organization: anthropic/_index
    note: Core Contributor
  - title: Nicholas L. Turner
    organization: anthropic/_index
    note: Core Contributor
  - title: Craig Citro
    organization: anthropic/_index
    note: Core Contributor
  - title: David Abrahams
    organization: anthropic/_index
  - title: Shan Carter
    organization: anthropic/_index
  - title: Basil Hosmer
    organization: anthropic/_index
  - title: Jonathan Marcus
    organization: anthropic/_index
  - title: Michael Sklar
    organization: anthropic/_index
  - title: Adly Templeton
    organization: anthropic/_index
  - title: Trenton Bricken
    organization: anthropic/_index
  - title: Callum McDougall
    organization: anthropic/_index
    note: Work performed while at Anthropic
  - title: Hoagy Cunningham
    organization: anthropic/_index
  - title: Thomas Henighan
    organization: anthropic/_index
  - title: Adam Jermyn
    organization: anthropic/_index
  - title: Andy Jones
    organization: anthropic/_index
  - title: Andrew Persic
    organization: anthropic/_index
  - title: Zhenyi Qi
    organization: anthropic/_index
  - title: T. Ben Thompson
    organization: anthropic/_index
  - title: Sam Zimmerman
    organization: anthropic/_index
  - title: Kelley Rivoire
    organization: anthropic/_index
  - title: Thomas Conerly
    organization: anthropic/_index
  - title: Chris Olah
    organization: anthropic/_index
  - title: Joshua Batson
    organization: anthropic/_index
    note: Core Contributor, Correspondence to joshb@anthropic.com
categories:
  - ai/_index
tags:
  - large language models
  - AI ethics
  - constitutional AI
  - AI alignment
  - AI safety
  - AI transparency
resource_type: research paper
summary: |
  Large language models display impressive capabilities. However, for the most part, the mechanisms by which they do so are unknown. The black-box nature of models is increasingly unsatisfactory as they advance in intelligence and are deployed in a growing number of applications. Our goal is to reverse engineer how these models work on the inside, so we may better understand them and assess their fitness for purpose.

  The challenges we face in understanding language models resemble those faced by biologists. Living organisms are complex systems which have been sculpted by billions of years of evolution. While the basic principles of evolution are straightforward, the biological mechanisms it produces are spectacularly intricate. Likewise, while language models are generated by simple, human-designed training algorithms, the mechanisms born of these algorithms appear to be quite complex.
source_url: https://transformer-circuits.pub/2025/attribution-graphs/biology.html
source_organizations:
  - anthropic/_index
language: en
---