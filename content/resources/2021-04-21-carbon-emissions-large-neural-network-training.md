---
title: Carbon Emissions and Large Neural Network Training
publication_date: 2021-04-21
authors:
  - title: David Patterson
    organization: google/_index
  - title: Joseph Gonzalez
    organization: uc-berkeley/_index
  - title: Quoc Le
    organization: google/_index
  - title: Chen Liang
    organization: google/_index
  - title: Lluis-Miquel Munguia
    organization: google/_index
  - title: Daniel Rothchild
    organization: uc-berkeley/_index
  - title: David So
    organization: google/_index
  - title: Maud Texier
    organization: google/_index
  - title: Jeff Dean
    organization: google/_index
categories:
  - sustainable/_index
tags:
  - environmental impact
  - AI
  - Neural Networks
  - Carbon footprint
  - Cloud Computing
resource_type: research
summary: |
  This comprehensive study analyzes the real carbon footprint of training large neural network models, taking into account multiple often-overlooked factors.

  The research provides a detailed methodology for calculating CO2 emissions and demonstrates how the choice of data center location and timing can significantly impact the environmental cost of AI training.

  The authors show that thoughtful choices about where and when to train models can reduce CO2 emissions by up to 100x compared to random choices.
source_url: https://arxiv.org/abs/2104.10350
source_document: https://arxiv.org/pdf/2104.10350.pdf
source_organizations:
  - google/_index
  - uc-berkeley/_index
  - google/_index
language: en
--- 